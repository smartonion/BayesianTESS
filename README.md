# BayesianTESS
Applying Bayesian Methods in Machine Learning on TESS Light Curves

## What's been done

Added the TOI dataset from NASA Exoplanet Archive. Created a processing script that converts the raw TOI data into a clean format with one row per star. The script filters out ambiguous cases and dispositions we don't want (PC, APC, KP), and creates binary labels: 1 for confirmed planets, 0 for false positives/alarms. Output is saved to `dataset/toi_per_star_labels.csv` with columns: tic_id, label, period_days, t0_bjd. This is the file that'll be used for the GP training pipeline.

Built a complete data pipeline for downloading and processing TESS light curves. Created scripts to download SPOC light curve FITS files from MAST, convert them to compressed NPZ format, and handle cases where stars don't have SPOC data available. The main script is `scripts/build_dataset.py` which does everything automatically - creates a subset of 60 confirmed planet stars and 90 false positive stars, downloads their light curves, converts to NPZ, and automatically backfills any stars that don't have data available. The script has resume logic so it can be interrupted and restarted without re-downloading or re-converting existing files. Final output is `dataset/index.csv` which defines the training data contract with columns: tic_id, npz_path, label, period_days, t0_bjd. Each NPZ file contains time, flux, flux error, quality flags, and metadata arrays sorted by time with NaN values filtered out. The dataset is ready for GP training with exactly 150 stars all having valid light curve data.