# BayesianTESS
Applying Bayesian Methods in Machine Learning on TESS Light Curves

## What's been done

Added the TOI dataset from NASA Exoplanet Archive. Created a processing script that converts the raw TOI data into a clean format with one row per star. The script filters out ambiguous cases and dispositions we don't want (PC, APC, KP), and creates binary labels: 1 for confirmed planets, 0 for false positives/alarms. Output is saved to `dataset/toi_per_star_labels.csv` with columns: tic_id, label, period_days, t0_bjd. This is the file that'll be used for the GP training pipeline.

Built a complete data pipeline for downloading and processing TESS light curves. Created scripts to download SPOC light curve FITS files from MAST, convert them to compressed NPZ format, and handle cases where stars don't have SPOC data available. The main script is `scripts/build_dataset.py` which does everything automatically - creates a subset of 60 confirmed planet stars and 90 false positive stars, downloads their light curves, converts to NPZ, and automatically backfills any stars that don't have data available. The script has resume logic so it can be interrupted and restarted without re-downloading or re-converting existing files. Final output is `dataset/index.csv` which defines the training data contract with columns: tic_id, npz_path, label, period_days, t0_bjd. Each NPZ file contains time, flux, flux error, quality flags, and metadata arrays sorted by time with NaN values filtered out. The dataset is ready for GP training with exactly 150 stars all having valid light curve data.

Created a class-based DataLoader in `models/data_loader.py` that aggregates light curve data into lists for ML training. The DataLoader reads from `index.csv`, loads all NPZ files, and returns (X, y) where X is a list of flux arrays and y is a numpy array of binary labels. It reuses existing functionality from `gp_data.py` and handles path resolution automatically. Comprehensive test suite in `test_data_loader.py` validates correctness, edge cases, and integration with existing code.

Implemented feature extraction for baseline GP model in `models/features.py`. Extracts 6 features from light curves: mean, std, skewness, kurtosis, dominant period, and peak power. Features are computed on normalized flux (median normalization) and include both statistical and frequency domain analysis. Created `scripts/build_feature_matrix.py` that processes all stars from the training index, extracts features, and saves the feature matrix (X) and labels (y) to disk as NumPy arrays for baseline GP model training.